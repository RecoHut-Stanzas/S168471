{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GroupIM: A Mutual Information Maximization Framework for Neural Group Recommendation\n",
        "\n",
        "## Executive summary\n",
        "\n",
        "| | |\n",
        "| --- | --- |\n",
        "| Problem | Group interactions are sparse in nature which makes it difficult to provide relevant recommendation to the group. |\n",
        "| Solution | Regularize the user-group latent space to overcome group interaction sparsity by: maximizing mutual information between representations of groups and group members; and dynamically prioritizing the preferences of highly informative members through contextual preference weighting. |\n",
        "| Dataset | Weeplaces |\n",
        "| Preprocessing | We extract check-ins on POIs over all major cities in the United States, across various categories including Food, Nightlife, Outdoors, Entertainment and Travel. We randomly split the set of all groups into training (70%), validation (10%), and test (20%) sets, while utilizing the individual interactions of all users for training. Note that each group appears only in one of the three sets. The test set contains strict ephemeral groups (i.e., a specific combination of users) that do not occur in the training set. Thus, we train on ephemeral groups and test on strict ephemeral groups. |\n",
        "| Metrics | NDCG, Recall |\n",
        "| Hyperparams | We tune the latent dimension in the range {32, 64, 128} and other baseline hyper-parameters in ranges centered at author-provided values. In GroupIM, we use two fully connected layers of size 64 each in fenc(·) and tune λ in the range {$2^{−4}$,$2^{−3}$,$\\dots$, $2^{6}$}. We use 5 negatives for each true user-group pair to train the discriminator. |\n",
        "| Models | GroupIM along with Encoder, 3 types of Aggregators to choose from, and a discriminator module. |\n",
        "| Platform | PyTorch, preferable GPU for faster computation. |\n",
        "| Links | [Paper](https://arxiv.org/abs/2006.03736), [Code](https://github.com/RecoHut-Stanzas/S168471) |\n",
        "\n",
        "## Tutorials\n",
        "\n",
        "### Training GroupIM model (PyTorch) on Weeplaces dataset\n",
        "\n",
        "[direct link to notebook →](https://t.ly/Nicx)\n",
        "\n",
        "In this notebook, we are first fetching a preprocessed version of the Weeplaces dataset from the *RecoHut-Datasets* server. Then we are building a dataset class module inheriting from the pytorch’s Dataset. We then implement GroupIM model along with Encoder, 3 types of Aggregators to choose from, and a discriminator module. All these modules are inherited from the pytorch’s `nn.Module`. Then we implement metrics and evaluation functions and train the model.\n",
        "\n",
        "## References\n",
        "\n",
        "1. [https://arxiv.org/abs/2006.03736](https://arxiv.org/abs/2006.03736)\n",
        "2. [https://github.com/RecoHut-Stanzas/S168471](https://github.com/RecoHut-Stanzas/S168471)"
      ],
      "metadata": {
        "id": "lIYdn1woOS1n"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}